{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineer Challenge\n",
    "\n",
    "Este notebook documenta la soluciÃ³n completa al desafÃ­o, incluyendo la organizaciÃ³n del repositorio, los enfoques de optimizaciÃ³n en tiempo y memoria, el benchmarking de los backends y un anexo de verificaciÃ³n de resultados.\n",
    "\n",
    "---\n",
    "\n",
    "En primer lugar, se debe descargar el archivo `farmers-protest-tweets-2021-2-4.json` y almacenarlo en una carpeta llamada `data` en la raiz. Esto puede hacerse manualmente o ejecutando el siguiente bloque de cÃ³digo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo JSON ya existe en: ../data/farmers-protest-tweets-2021-2-4.json\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import subprocess\n",
    "import sys\n",
    "import zipfile\n",
    "\n",
    "data_dir = Path(\"../data\")\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "json_path = data_dir / \"farmers-protest-tweets-2021-2-4.json\"\n",
    "zip_path = data_dir / \"farmers-protest-tweets-2021-2-4.json.zip\"\n",
    "\n",
    "if not json_path.exists():\n",
    "    if not zip_path.exists():\n",
    "        try:\n",
    "            import gdown\n",
    "        except ImportError:\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"gdown\"], check=True)\n",
    "            import gdown\n",
    "\n",
    "        url = \"https://drive.google.com/uc?id=1ig2ngoXFTxP5Pa8muXo02mDTFexZzsis\"\n",
    "        print(f\"Descargando ZIP a {zip_path} ...\")\n",
    "        gdown.download(url, str(zip_path), quiet=False)\n",
    "\n",
    "    print(f\"Descomprimiendo {zip_path} ...\")\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
    "        zf.extractall(path=data_dir)\n",
    "\n",
    "    zip_path.unlink()\n",
    "\n",
    "    print(f\"Archivo JSON disponible en: {json_path}\")\n",
    "else:\n",
    "    print(f\"El archivo JSON ya existe en: {json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Estructura del repositorio\n",
    "\n",
    "La estructura principal del repositorio es la siguiente:\n",
    "\n",
    "```\n",
    "| .\n",
    "| â”œâ”€â”€ data/\n",
    "| â”‚   â””â”€â”€ farmers-protest-tweets-2021-2-4.json   <-- Archivo del desafÃ­o\n",
    "| â”œâ”€â”€ src/\n",
    "| |   â”œâ”€â”€ challenge.ipynb                  <-- Notebook principal con la soluciÃ³n al desafÃ­o\n",
    "| â”‚   â”œâ”€â”€ backend/\n",
    "| â”‚   â”‚   â”œâ”€â”€ pandas_backend.py            <-- Funciones utilizando Pandas\n",
    "| â”‚   â”‚   â”œâ”€â”€ polars_backend.py            <-- Funciones utilizando Polars\n",
    "| â”‚   â”‚   â”œâ”€â”€ duckdb_backend.py            <-- Funciones utilizando DuckDB\n",
    "| â”‚   â”‚   â””â”€â”€ ijson_backend.py             <-- Funciones utilizando ijson\n",
    "| â”‚   â”œâ”€â”€ q1_time.py                       <-- q1 optimizada en tiempo\n",
    "| â”‚   â”œâ”€â”€ q1_memory.py                     <-- q1 optimizada en memoria\n",
    "| â”‚   â”œâ”€â”€ q2_time.py                       <-- q2 optimizada en tiempo\n",
    "| â”‚   â”œâ”€â”€ q2_memory.py                     <-- q2 optimizada en memoria\n",
    "| â”‚   â”œâ”€â”€ q3_time.py                       <-- q3 optimizada en tiempo\n",
    "| â”‚   â”œâ”€â”€ q3_memory.py                     <-- q3 optimizada en memoria\n",
    "| â”‚   â””â”€â”€ benchmark/\n",
    "| â”‚       â”œâ”€â”€ benchmark_script.py          <-- Script independiente de benchmarking\n",
    "| â”‚       â””â”€â”€ benchmark.ipynb              <-- Notebook de benchmarking detallado\n",
    "| â”œâ”€â”€ profile_reports/\n",
    "| â”‚   â”œâ”€â”€ cprofile_combined.txt            <-- Reporte Ãºnico de cProfile\n",
    "| â”‚   â””â”€â”€ master_summary.csv               <-- CSV con todas las mÃ©tricas\n",
    "| â”œâ”€â”€ run_all_benchmarks.sh                <-- Script maestro para invocar el benchmarking\n",
    "| â”œâ”€â”€ requirements.txt                     <-- Versiones de librerÃ­as usadas\n",
    "| â”œâ”€â”€ tests/\n",
    "| â”‚   â”œâ”€â”€ conftest.py                      <-- Fixture de pytest que parametriza backends\n",
    "| â”‚   â”œâ”€â”€ data_fixtures.py                 <-- CreaciÃ³n de archivos NDJSON temporales\n",
    "| â”‚   â”œâ”€â”€ loaders/\n",
    "| â”‚   â”‚   â”œâ”€â”€ test_duckdb_loader.py        <-- Tests de helpers de DuckDB\n",
    "| â”‚   â”‚   â”œâ”€â”€ test_pandas_loader.py        <-- Tests de helpers de Pandas\n",
    "| â”‚   â”‚   â””â”€â”€ test_polars_loader.py        <-- Tests de helpers de Polars\n",
    "| â”‚   â””â”€â”€ business/\n",
    "| â”‚       â”œâ”€â”€ test_top_active_dates.py     <-- Tests de negocio para top_active_dates\n",
    "| â”‚       â”œâ”€â”€ test_top_emojis.py           <-- Tests de negocio para top_emojis\n",
    "| â”‚       â””â”€â”€ test_top_mentioned_users.py  <-- Tests de negocio para top_mentioned_users\n",
    "| â””â”€â”€ README.md                            <-- DescripciÃ³n general y pasos para ejecutar\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo\n",
    "data_path = Path(\"../data/farmers-protest-tweets-2021-2-4.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Enfoque general\n",
    "\n",
    "1. **SeparaciÃ³n de funciones y backends**  \n",
    "   Cada pregunta (q1, q2 y q3) se resuelve con dos funciones:\n",
    "   - Una versiÃ³n **optimizada en tiempo** (`qX_time.py`), usando polars.\n",
    "   - Una versiÃ³n **optimizada en memoria** (`qX_memory.py`), usando `ijson`.\n",
    "\n",
    "2. **Backends modulares en `src/backend/`**  \n",
    "   - `pandas_backend.py`  \n",
    "   - `polars_backend.py`  \n",
    "   - `duckdb_backend.py`  \n",
    "   - `ijson_backend.py`  \n",
    "   Cada uno expone funciones genÃ©ricas (`top_active_dates`, `top_emojis`, `top_mentioned_users`) que se emplean para medir rendimiento.\n",
    "\n",
    "3. **Benchmark independiente**  \n",
    "   - El archivo `src/benchmark/benchmark_script.py` ejecuta cada combinaciÃ³n `backend + funciÃ³n` en un **proceso aislado**.  \n",
    "   - El script genera un CSV acumulativo (`profile_reports/master_summary.csv`) y opcionalmente un Ãºnico archivo de texto con todos los reportes de `cProfile`.  \n",
    "   - El script maestro `run_all_benchmarks.sh` lanza las 12 pruebas (4 backends Ã— 3 funciones).\n",
    "\n",
    "4. **Notebook de benchmark**  \n",
    "   Para mÃ¡s detalles del benchmark, detalles del optimo de memoria/tiempo y como se escogiÃ³n la opciÃ³n Ã³ptima para cada caso, ir al notebook correspondiente al benchmarking.\n",
    "   - `src/benchmark/benchmark.ipynb` importa `profile_reports/master_summary.csv` y genera grÃ¡ficos comparativos por funciÃ³n (tiempo y memoria).  \n",
    "  A continuaciÃ³n podemos ver un pequeÃ±o cuadro resumen del benchmark:\n",
    "\n",
    "| FunciÃ³n               | Backend | Tiempo (s) | Peak de memoria (MB) |\n",
    "|-----------------------|---------|------------|-------------------|\n",
    "| **top_active_dates**  | pandas  | 1.977      | 515.30            |\n",
    "|                       | polars  | 0.753      | 751.41            |\n",
    "|                       | duckdb  | 0.898      | 1626.23           |\n",
    "|                       | ijson   | 2.749      | 101.88            |\n",
    "| **top_emojis**        | pandas  | 1.716      | 187.78            |\n",
    "|                       | polars  | 0.109      | 549.78            |\n",
    "|                       | duckdb  | 0.646      | 534.25            |\n",
    "|                       | ijson   | 1.853      | 90.03             |\n",
    "| **top_mentioned_users** | pandas  | 1.741      | 274.47            |\n",
    "|                         | polars  | 0.354      | 1241.73           |\n",
    "|                         | duckdb  | 0.403      | 847.69            |\n",
    "|                         | ijson   | 2.920      | 94.48             |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LibrerÃ­as y herramientas usadas\n",
    "\n",
    "- **cProfile** + **pstats**: para mediciÃ³n detallada de tiempo de CPU, nÃºmero de llamadas y estadÃ­sticas acumuladas.  \n",
    "- **memory-profiler**: para muestreo y captura del peak de memoria residente durante la ejecuciÃ³n.  \n",
    "- **ijson**: para lecturas en streaming y minimizaciÃ³n de uso de memoria en las funciones optimizadas en memoria.  \n",
    "- **Pandas**, **Polars**, **DuckDB**: diferentes enfoques en tiempo con estructuras tabulares/columnar/SQL embebido.  \n",
    "- **Matplotlib**: para graficar comparaciones de tiempo y memoria en el notebook de benchmarking.  \n",
    "- **Argparse**: en `benchmark_script.py` para recibir parÃ¡metros de lÃ­nea de comandos.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SoluciÃ³n detallada de cada pregunta\n",
    "\n",
    "### 4.1. Q1: Top 10 fechas con mÃ¡s tweets (+ usuario que mÃ¡s tuitea)\n",
    "\n",
    "- **VersiÃ³n optimizada en tiempo**  \n",
    "  Se usÃ³ **Polars** para:\n",
    "  1. `scan_ndjson()` para leer Ãºnicamente las columnas `date` y `user`.\n",
    "  2. Convertir el campo de fecha a tipo `Datetime` y luego extraer la columna `dt` (solo fecha).\n",
    "  3. Extraer `user.username` en forma de columna.\n",
    "  4. Agrupar por `(dt, username)` y contar en paralelo.\n",
    "  5. Obtener el usuario con mayor count por fecha (`group_by(\"dt\").first()` tras ordenar).\n",
    "  6. Calcular el total de tweets por `dt` y ordenar para elegir las 10 fechas con mÃ¡s tweets.\n",
    "\n",
    "- **VersiÃ³n optimizada en memoria**  \n",
    "  Se usÃ³ **ijson** para:\n",
    "  1. Abrir el archivo en modo streaming y recorrer cada tweet uno a uno.\n",
    "  2. Para cada tweet, extraer la fecha (`fecha = date.fromisoformat(date_str[:10])`) y `username`.\n",
    "  3. Incrementar un `Counter` global para contar tweets totales por fecha.\n",
    "  4. Mantener un diccionario de `Counter` por fecha que acumula conteo de tuits por usuario.\n",
    "  5. Al finalizar la lectura, calcular manualmente las 10 fechas con mayor total y extraer el usuario mÃ¡s frecuente en cada fecha.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1 optimizada en memoria\n",
    "from q1_memory import q1_memory\n",
    "\n",
    "q1_memory_result = q1_memory(data_path)\n",
    "q1_memory_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1 optimizada en tiempo\n",
    "from q1_time import q1_time\n",
    "\n",
    "q1_time_result = q1_time(data_path)\n",
    "q1_time_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Q2: Top 10 emojis mÃ¡s usados (con su conteo)\n",
    "\n",
    "- **VersiÃ³n optimizada en tiempo**  \n",
    "  - Se usÃ³ **Polars** para:  \n",
    "    1. `scan_ndjson()` lee Ãºnicamente la columna `content` en modo lazy.  \n",
    "    2. Filtra tweets con contenido no nulo.  \n",
    "    3. Crea una expresiÃ³n que extrae todos los emojis usando una expresiÃ³n regular Unicode (`\\p{Extended_Pictographic}`) en forma vectorizada.  \n",
    "    4. Aplana la lista de emojis, agrupa por cada sÃ­mbolo y cuenta en paralelo.  \n",
    "    5. Ordena por frecuencia y toma los 10 emojis mÃ¡s frecuentes.  \n",
    "\n",
    "- **VersiÃ³n optimizada en memoria**  \n",
    "  - Se usÃ³ **ijson** para:  \n",
    "    1. Abrir el archivo NDJSON en modo streaming y procesar tweet a tweet.  \n",
    "    2. Para cada tweet, extraer el campo `content` y aplicar un patrÃ³n `regex` Python `r\"\\p{Extended_Pictographic}\"` para extraer emojis.  \n",
    "    3. Mantener un `Counter` que acumula la frecuencia de cada emoji encontrado.  \n",
    "    4. Al terminar, devolver los 10 emojis mÃ¡s comunes.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ğŸ™', 7286),\n",
       " ('ğŸ˜‚', 3072),\n",
       " ('ğŸšœ', 2972),\n",
       " ('âœŠ', 2411),\n",
       " ('ğŸŒ¾', 2363),\n",
       " ('â¤', 1779),\n",
       " ('ğŸ¤£', 1668),\n",
       " ('ğŸ‘‡', 1108),\n",
       " ('ğŸ’š', 1040),\n",
       " ('ğŸ’ª', 947)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2 optimizada en memoria\n",
    "from q2_memory import q2_memory\n",
    "\n",
    "q2_memory_result = q2_memory(data_path)\n",
    "q2_memory_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ğŸ™', 7286),\n",
       " ('ğŸ˜‚', 3072),\n",
       " ('ğŸšœ', 2972),\n",
       " ('âœŠ', 2411),\n",
       " ('ğŸŒ¾', 2363),\n",
       " ('â¤', 1779),\n",
       " ('ğŸ¤£', 1668),\n",
       " ('ğŸ‘‡', 1108),\n",
       " ('ğŸ’š', 1040),\n",
       " ('ğŸ’ª', 947)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2 optimizada en tiempo\n",
    "from q2_time import q2_time\n",
    "\n",
    "q2_time_result = q2_time(data_path)\n",
    "q2_time_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Q3: Top 10 usuarios mÃ¡s mencionados (conteo de `@username`)\n",
    "\n",
    "- **VersiÃ³n optimizada en tiempo**  \n",
    "  - Se usÃ³ **Polars** para:  \n",
    "    1. `scan_ndjson()` lee Ãºnicamente la columna `mentionedUsers` en modo lazy.  \n",
    "    2. Explota la columna de listas de menciones (`explode(\"mentionedUsers\")`).  \n",
    "    3. Mapea cada elemento (un objeto JSON) a su campo `username`.  \n",
    "    4. Filtra nulos, agrupa por cada `username` y cuenta en paralelo.  \n",
    "    5. Ordena por frecuencia y toma los 10 usuarios mÃ¡s mencionados.  \n",
    "\n",
    "- **VersiÃ³n optimizada en memoria**  \n",
    "  - Se usa **ijson** para:  \n",
    "    1. Leer el NDJSON en streaming, tweet a tweet.  \n",
    "    2. Para cada tweet, extraer la lista `mentionedUsers`.  \n",
    "    3. Iterar esa lista y, por cada diccionario de menciÃ³n, extraer `username` y actualizar un `Counter`.  \n",
    "    4. Al finalizar la lectura, retornar los 10 usuarios mÃ¡s frecuentes del `Counter`.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('narendramodi', 2265),\n",
       " ('Kisanektamorcha', 1840),\n",
       " ('RakeshTikaitBKU', 1644),\n",
       " ('PMOIndia', 1427),\n",
       " ('RahulGandhi', 1146),\n",
       " ('GretaThunberg', 1048),\n",
       " ('RaviSinghKA', 1019),\n",
       " ('rihanna', 986),\n",
       " ('UNHumanRights', 962),\n",
       " ('meenaharris', 926)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3 optimizada en memoria\n",
    "from q3_memory import q3_memory\n",
    "\n",
    "q3_memory_result = q3_memory(data_path)\n",
    "q3_memory_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('narendramodi', 2265),\n",
       " ('Kisanektamorcha', 1840),\n",
       " ('RakeshTikaitBKU', 1644),\n",
       " ('PMOIndia', 1427),\n",
       " ('RahulGandhi', 1146),\n",
       " ('GretaThunberg', 1048),\n",
       " ('RaviSinghKA', 1019),\n",
       " ('rihanna', 986),\n",
       " ('UNHumanRights', 962),\n",
       " ('meenaharris', 926)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3 optimizada en tiempo\n",
    "from q3_time import q3_time\n",
    "\n",
    "q3_time_result = q3_time(data_path)\n",
    "q3_time_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Unit Testing\n",
    "\n",
    "Para garantizar la correcta funcionalidad â€”y la consistencia entre backendsâ€” se implementÃ³ una baterÃ­a completa de tests con **pytest**, organizada en `tests/`.\n",
    "\n",
    "### 5.1. Estrategia\n",
    "\n",
    "1. **ParametrizaciÃ³n por backend**  \n",
    "   - Con `conftest.py` se importa dinÃ¡micamente cada mÃ³dulo (`pandas_backend`, `polars_backend`, `duckdb_backend`, `ijson_backend`).  \n",
    "   - Cada test de negocio (`top_active_dates`, `top_emojis`, `top_mentioned_users`) se ejecuta **cuatro veces**, una por backend.\n",
    "\n",
    "2. **Fixtures auto-contenidas**  \n",
    "   - `tests/data_fixtures.py` crea archivos NDJSON temporales usando `tmp_path`, de modo que los tests no dependen de archivos reales ni de conexiÃ³n externa.  \n",
    "   - Se cubren escenarios:\n",
    "     - Datos â€œfelicesâ€ (`sample_data_path`)  \n",
    "     - Casos con valores nulos (`sample_data_with_nulls`)  \n",
    "     - Dataset sin emojis (`sample_data_no_emoji`)\n",
    "\n",
    "3. **Cobertura de helpers**  \n",
    "   - Se testean tambiÃ©n las funciones auxiliares internas (`_lazy_scan`, `_load_ndjson`, `_get_connection`, etc.), verificando manejo de rutas inexistentes y retorno de estructuras correctas.\n",
    "\n",
    "### 5.2. Resultados de cobertura\n",
    "\n",
    "| Name                            | Stmts | Miss | Cover |\n",
    "|---------------------------------|-------|------|-------|\n",
    "| src/backend/__init__.py         | 0     | 0    | 100%  |\n",
    "| src/backend/duckdb_backend.py   | 59    | 3    | 95%   |\n",
    "| src/backend/ijson_backend.py    | 92    | 14   | 85%   |\n",
    "| src/backend/pandas_backend.py   | 56    | 3    | 95%   |\n",
    "| src/backend/polars_backend.py   | 39    | 3    | 92%   |\n",
    "| **TOTAL**                       | 246   | 23   | 91%   |\n",
    "\n",
    "- **Cobertura global:** **91 %** (44 tests, ~0.6 s).  \n",
    "- **Rango por archivo:** 85 % â€“ 95 %.\n",
    "\n",
    "### 5.3. Deuda tÃ©cnica\n",
    "\n",
    "Aunque un 91 % es aceptable, mi objetivo habitual es mÃ¡s de 95 %.  \n",
    "Por limitaciones de tiempo dejÃ© pendiente:\n",
    "\n",
    "| Archivo | Pendiente | Impacto |\n",
    "|---------|-----------|---------|\n",
    "| `ijson_backend.py` | Verificar rutas de error en `_parse_ndjson_stream` y branches que manejan objetos JSON anidados poco comunes. | +3/4 % cobertura |\n",
    "| `duckdb_backend.py` | Tests sobre manejo de tweets sin campo `mentionedUsers` y fechas malformadas. | +1/2 % cobertura |\n",
    "| Casos borde globales | Archivos vacÃ­os, lÃ­neas en blanco mÃºltiples, mezclas de codificaciones. | Robustece producciÃ³n |\n",
    "\n",
    "Esta mejora queda como **deuda tÃ©cnica**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusiones finales y elecciÃ³n de frameworks\n",
    "\n",
    "1. **Resultados clave**  \n",
    "   - **Polars** fue el backend mÃ¡s rÃ¡pido en las tres funciones.  \n",
    "   - **ijson** alcanzÃ³ siempre el menor peak de memoria.  \n",
    "   - **Pandas** ofreciÃ³ un equilibrio razonable (tiempo medio, memoria contenida).  \n",
    "   - **DuckDB** igualÃ³ a Polars en tiempo en algunos casos, pero con mayor uso de RAM.\n",
    "\n",
    "2. **Supuesto: ejecuciÃ³n local**  \n",
    "   Aunque el desafÃ­o permite usar plataformas cloud, decidÃ­ perfilar en modo single-node por:\n",
    "   - **Volumen**: 400 MB caben cÃ³modamente en la RAM de un portÃ¡til; no se requiere cluster.  \n",
    "   - **Reproducibilidad rÃ¡pida**: quien revise el repo puede correr todo en su mÃ¡quina sin credenciales externas.  \n",
    "   - **Plazo corto** (4 dÃ­as): evita sobrecarga de aprovisionar servicios.\n",
    "\n",
    "   > *Este es un supuesto mÃ­o; no es una exigencia del enunciado.*\n",
    "\n",
    "3. **CuÃ¡ndo migrar a BigQuery / Dataflow / DataProc**  \n",
    "   | Escenario | Ventaja cloud-scale |\n",
    "   |-----------|--------------------|\n",
    "   | Datasets de **10 GB â€“ TB** | AlmacÃ©n columnar distribuido (BigQuery) o Spark (DataProc) para escaneo paralelo. |\n",
    "   | **ETL recurrente** | Apache Beam (runner Dataflow) gestiona ventanas, reintentos y autoscaling. |\n",
    "   | **Consultas ad-hoc multi-usuario** | BigQuery ofrece capacidad elÃ¡stica sin afectar a otros workloads. |\n",
    "   | **SLA estrictos** o alta concurrencia | Delegar tolerancia a fallos y escalado horizontal al proveedor. |\n",
    "\n",
    "4. **ConclusiÃ³n prÃ¡ctica**  \n",
    "   - Para el dataset del reto, **Polars + ijson** cubren los extremos de velocidad y frugalidad en RAM con complejidad mÃ­nima.  \n",
    "   - En proyectos productivos con fuentes continuas o volÃºmenes muy superiores, escalar a servicios cloud serÃ­a lo apropiado; las funciones aquÃ­ implementadas podrÃ­an portarse a PySpark, Beam o consultas SQL en BigQuery sin cambiar la lÃ³gica de negocio.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Anexo - EjecuciÃ³n de todos los backends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Top 10 dates with the most tweets and their most active user:**\n",
      "\n",
      " 1. Date: 2021-02-12   â€”   User with the most tweets: RanbirS00614606\n",
      " 2. Date: 2021-02-13   â€”   User with the most tweets: MaanDee08215437\n",
      " 3. Date: 2021-02-17   â€”   User with the most tweets: RaaJVinderkaur\n",
      " 4. Date: 2021-02-16   â€”   User with the most tweets: jot__b\n",
      " 5. Date: 2021-02-14   â€”   User with the most tweets: rebelpacifist\n",
      " 6. Date: 2021-02-18   â€”   User with the most tweets: neetuanjle_nitu\n",
      " 7. Date: 2021-02-15   â€”   User with the most tweets: jot__b\n",
      " 8. Date: 2021-02-20   â€”   User with the most tweets: MangalJ23056160\n",
      " 9. Date: 2021-02-23   â€”   User with the most tweets: Surrypuria\n",
      "10. Date: 2021-02-19   â€”   User with the most tweets: Preetm91\n",
      "\n",
      "**Top 10 most used emojis (emoji â€” frequency):**\n",
      "\n",
      " 1. ğŸ™   â€”   7286\n",
      " 2. ğŸ˜‚   â€”   3072\n",
      " 3. ğŸšœ   â€”   2972\n",
      " 4. âœŠ   â€”   2411\n",
      " 5. ğŸŒ¾   â€”   2363\n",
      " 6. â¤   â€”   1779\n",
      " 7. ğŸ¤£   â€”   1668\n",
      " 8. ğŸ‘‡   â€”   1108\n",
      " 9. ğŸ’š   â€”   1040\n",
      "10. ğŸ’ª   â€”   947\n",
      "\n",
      "**Top 10 most mentioned users (user â€” frequency):**\n",
      "\n",
      " 1. narendramodi   â€”   2265\n",
      " 2. Kisanektamorcha   â€”   1840\n",
      " 3. RakeshTikaitBKU   â€”   1644\n",
      " 4. PMOIndia   â€”   1427\n",
      " 5. RahulGandhi   â€”   1146\n",
      " 6. GretaThunberg   â€”   1048\n",
      " 7. RaviSinghKA   â€”   1019\n",
      " 8. rihanna   â€”   986\n",
      " 9. UNHumanRights   â€”   962\n",
      "10. meenaharris   â€”   926\n"
     ]
    }
   ],
   "source": [
    "from backend.polars_backend import (\n",
    "    top_active_dates,\n",
    "    top_emojis,\n",
    "    top_mentioned_users\n",
    ")\n",
    "\n",
    "# Top Active Dates\n",
    "n_dates = 10\n",
    "\n",
    "active_dates = top_active_dates(data_path, n=n_dates)\n",
    "\n",
    "print(f\"**Top {n_dates} dates with the most tweets and their most active user:**\\n\")\n",
    "for idx, (date, user) in enumerate(active_dates, start=1):\n",
    "    print(f\"{idx:2d}. Date: {date}   â€”   User with the most tweets: {user}\")\n",
    "\n",
    "# Top Emojis\n",
    "n_emojis = 10\n",
    "\n",
    "most_used_emojis = top_emojis(data_path, n=n_emojis)\n",
    "\n",
    "print(f\"\\n**Top {n_emojis} most used emojis (emoji â€” frequency):**\\n\")\n",
    "for idx, (emoji, frequency) in enumerate(most_used_emojis, start=1):\n",
    "    print(f\"{idx:2d}. {emoji}   â€”   {frequency}\")\n",
    "\n",
    "# Top Mentions\n",
    "n_mentions = 10\n",
    "\n",
    "most_mentioned_users = top_mentioned_users(data_path, n=n_mentions)\n",
    "\n",
    "print(f\"\\n**Top {n_mentions} most mentioned users (user â€” frequency):**\\n\")\n",
    "for idx, (user, count) in enumerate(most_mentioned_users, start=1):\n",
    "    print(f\"{idx:2d}. {user}   â€”   {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Top 10 dates with the most tweets and their most active user:**\n",
      "\n",
      " 1. Date: 2021-02-12   â€”   User with the most tweets: RanbirS00614606\n",
      " 2. Date: 2021-02-13   â€”   User with the most tweets: MaanDee08215437\n",
      " 3. Date: 2021-02-17   â€”   User with the most tweets: RaaJVinderkaur\n",
      " 4. Date: 2021-02-16   â€”   User with the most tweets: jot__b\n",
      " 5. Date: 2021-02-14   â€”   User with the most tweets: rebelpacifist\n",
      " 6. Date: 2021-02-18   â€”   User with the most tweets: neetuanjle_nitu\n",
      " 7. Date: 2021-02-15   â€”   User with the most tweets: jot__b\n",
      " 8. Date: 2021-02-20   â€”   User with the most tweets: MangalJ23056160\n",
      " 9. Date: 2021-02-23   â€”   User with the most tweets: Surrypuria\n",
      "10. Date: 2021-02-19   â€”   User with the most tweets: Preetm91\n",
      "\n",
      "**Top 10 most used emojis (emoji â€” frequency):**\n",
      "\n",
      " 1. ğŸ™   â€”   7286\n",
      " 2. ğŸ˜‚   â€”   3072\n",
      " 3. ğŸšœ   â€”   2972\n",
      " 4. âœŠ   â€”   2411\n",
      " 5. ğŸŒ¾   â€”   2363\n",
      " 6. â¤   â€”   1779\n",
      " 7. ğŸ¤£   â€”   1668\n",
      " 8. ğŸ‘‡   â€”   1108\n",
      " 9. ğŸ’š   â€”   1040\n",
      "10. ğŸ’ª   â€”   947\n",
      "\n",
      "**Top 10 most mentioned users (user â€” frequency):**\n",
      "\n",
      " 1. narendramodi   â€”   2265\n",
      " 2. Kisanektamorcha   â€”   1840\n",
      " 3. RakeshTikaitBKU   â€”   1644\n",
      " 4. PMOIndia   â€”   1427\n",
      " 5. RahulGandhi   â€”   1146\n",
      " 6. GretaThunberg   â€”   1048\n",
      " 7. RaviSinghKA   â€”   1019\n",
      " 8. rihanna   â€”   986\n",
      " 9. UNHumanRights   â€”   962\n",
      "10. meenaharris   â€”   926\n"
     ]
    }
   ],
   "source": [
    "from backend.pandas_backend import (\n",
    "    top_active_dates,\n",
    "    top_emojis,\n",
    "    top_mentioned_users\n",
    ")\n",
    "\n",
    "# Top Active Dates\n",
    "n_dates = 10\n",
    "\n",
    "active_dates = top_active_dates(data_path, n=n_dates)\n",
    "\n",
    "print(f\"**Top {n_dates} dates with the most tweets and their most active user:**\\n\")\n",
    "for idx, (date, user) in enumerate(active_dates, start=1):\n",
    "    print(f\"{idx:2d}. Date: {date}   â€”   User with the most tweets: {user}\")\n",
    "\n",
    "# Top Emojis\n",
    "n_emojis = 10\n",
    "\n",
    "most_used_emojis = top_emojis(data_path, n=n_emojis)\n",
    "\n",
    "print(f\"\\n**Top {n_emojis} most used emojis (emoji â€” frequency):**\\n\")\n",
    "for idx, (emoji, frequency) in enumerate(most_used_emojis, start=1):\n",
    "    print(f\"{idx:2d}. {emoji}   â€”   {frequency}\")\n",
    "\n",
    "# Top Mentions\n",
    "n_mentions = 10\n",
    "\n",
    "most_mentioned_users = top_mentioned_users(data_path, n=n_mentions)\n",
    "\n",
    "print(f\"\\n**Top {n_mentions} most mentioned users (user â€” frequency):**\\n\")\n",
    "for idx, (user, count) in enumerate(most_mentioned_users, start=1):\n",
    "    print(f\"{idx:2d}. {user}   â€”   {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Top 10 dates with the most tweets and their most active user:**\n",
      "\n",
      " 1. Date: 2021-02-12   â€”   User with the most tweets: RanbirS00614606\n",
      " 2. Date: 2021-02-13   â€”   User with the most tweets: MaanDee08215437\n",
      " 3. Date: 2021-02-17   â€”   User with the most tweets: RaaJVinderkaur\n",
      " 4. Date: 2021-02-16   â€”   User with the most tweets: jot__b\n",
      " 5. Date: 2021-02-14   â€”   User with the most tweets: rebelpacifist\n",
      " 6. Date: 2021-02-18   â€”   User with the most tweets: neetuanjle_nitu\n",
      " 7. Date: 2021-02-15   â€”   User with the most tweets: jot__b\n",
      " 8. Date: 2021-02-20   â€”   User with the most tweets: MangalJ23056160\n",
      " 9. Date: 2021-02-23   â€”   User with the most tweets: Surrypuria\n",
      "10. Date: 2021-02-19   â€”   User with the most tweets: Preetm91\n",
      "\n",
      "**Top 10 most used emojis (emoji â€” frequency):**\n",
      "\n",
      " 1. ğŸ™   â€”   7286\n",
      " 2. ğŸ˜‚   â€”   3072\n",
      " 3. ğŸšœ   â€”   2972\n",
      " 4. âœŠ   â€”   2411\n",
      " 5. ğŸŒ¾   â€”   2363\n",
      " 6. â¤   â€”   1779\n",
      " 7. ğŸ¤£   â€”   1668\n",
      " 8. ğŸ‘‡   â€”   1108\n",
      " 9. ğŸ’š   â€”   1040\n",
      "10. ğŸ’ª   â€”   947\n",
      "\n",
      "**Top 10 most mentioned users (user â€” frequency):**\n",
      "\n",
      " 1. narendramodi   â€”   2265\n",
      " 2. Kisanektamorcha   â€”   1840\n",
      " 3. RakeshTikaitBKU   â€”   1644\n",
      " 4. PMOIndia   â€”   1427\n",
      " 5. RahulGandhi   â€”   1146\n",
      " 6. GretaThunberg   â€”   1048\n",
      " 7. RaviSinghKA   â€”   1019\n",
      " 8. rihanna   â€”   986\n",
      " 9. UNHumanRights   â€”   962\n",
      "10. meenaharris   â€”   926\n"
     ]
    }
   ],
   "source": [
    "from backend.duckdb_backend import (\n",
    "    top_active_dates,\n",
    "    top_emojis,\n",
    "    top_mentioned_users\n",
    ")\n",
    "\n",
    "# Top Active Dates\n",
    "n_dates = 10\n",
    "\n",
    "active_dates = top_active_dates(data_path, n=n_dates)\n",
    "\n",
    "print(f\"**Top {n_dates} dates with the most tweets and their most active user:**\\n\")\n",
    "for idx, (date, user) in enumerate(active_dates, start=1):\n",
    "    print(f\"{idx:2d}. Date: {date}   â€”   User with the most tweets: {user}\")\n",
    "\n",
    "# Top Emojis\n",
    "n_emojis = 10\n",
    "\n",
    "most_used_emojis = top_emojis(data_path, n=n_emojis)\n",
    "\n",
    "print(f\"\\n**Top {n_emojis} most used emojis (emoji â€” frequency):**\\n\")\n",
    "for idx, (emoji, frequency) in enumerate(most_used_emojis, start=1):\n",
    "    print(f\"{idx:2d}. {emoji}   â€”   {frequency}\")\n",
    "\n",
    "# Top Mentions\n",
    "n_mentions = 10\n",
    "\n",
    "most_mentioned_users = top_mentioned_users(data_path, n=n_mentions)\n",
    "\n",
    "print(f\"\\n**Top {n_mentions} most mentioned users (user â€” frequency):**\\n\")\n",
    "for idx, (user, count) in enumerate(most_mentioned_users, start=1):\n",
    "    print(f\"{idx:2d}. {user}   â€”   {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ijson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Top 10 dates with the most tweets and their most active user:**\n",
      "\n",
      " 1. Date: 2021-02-12   â€”   User with the most tweets: RanbirS00614606\n",
      " 2. Date: 2021-02-13   â€”   User with the most tweets: MaanDee08215437\n",
      " 3. Date: 2021-02-17   â€”   User with the most tweets: RaaJVinderkaur\n",
      " 4. Date: 2021-02-16   â€”   User with the most tweets: jot__b\n",
      " 5. Date: 2021-02-14   â€”   User with the most tweets: rebelpacifist\n",
      " 6. Date: 2021-02-18   â€”   User with the most tweets: neetuanjle_nitu\n",
      " 7. Date: 2021-02-15   â€”   User with the most tweets: jot__b\n",
      " 8. Date: 2021-02-20   â€”   User with the most tweets: MangalJ23056160\n",
      " 9. Date: 2021-02-23   â€”   User with the most tweets: Surrypuria\n",
      "10. Date: 2021-02-19   â€”   User with the most tweets: Preetm91\n",
      "\n",
      "**Top 10 most used emojis (emoji â€” frequency):**\n",
      "\n",
      " 1. ğŸ™   â€”   7286\n",
      " 2. ğŸ˜‚   â€”   3072\n",
      " 3. ğŸšœ   â€”   2972\n",
      " 4. âœŠ   â€”   2411\n",
      " 5. ğŸŒ¾   â€”   2363\n",
      " 6. â¤   â€”   1779\n",
      " 7. ğŸ¤£   â€”   1668\n",
      " 8. ğŸ‘‡   â€”   1108\n",
      " 9. ğŸ’š   â€”   1040\n",
      "10. ğŸ’ª   â€”   947\n",
      "\n",
      "**Top 10 most mentioned users (user â€” frequency):**\n",
      "\n",
      " 1. narendramodi   â€”   2265\n",
      " 2. Kisanektamorcha   â€”   1840\n",
      " 3. RakeshTikaitBKU   â€”   1644\n",
      " 4. PMOIndia   â€”   1427\n",
      " 5. RahulGandhi   â€”   1146\n",
      " 6. GretaThunberg   â€”   1048\n",
      " 7. RaviSinghKA   â€”   1019\n",
      " 8. rihanna   â€”   986\n",
      " 9. UNHumanRights   â€”   962\n",
      "10. meenaharris   â€”   926\n"
     ]
    }
   ],
   "source": [
    "from backend.ijson_backend import (\n",
    "    top_active_dates,\n",
    "    top_emojis,\n",
    "    top_mentioned_users\n",
    ")\n",
    "\n",
    "# Top Active Dates\n",
    "n_dates = 10\n",
    "\n",
    "active_dates = top_active_dates(data_path, n=n_dates)\n",
    "\n",
    "print(f\"**Top {n_dates} dates with the most tweets and their most active user:**\\n\")\n",
    "for idx, (date, user) in enumerate(active_dates, start=1):\n",
    "    print(f\"{idx:2d}. Date: {date}   â€”   User with the most tweets: {user}\")\n",
    "\n",
    "# Top Emojis\n",
    "n_emojis = 10\n",
    "\n",
    "most_used_emojis = top_emojis(data_path, n=n_emojis)\n",
    "\n",
    "print(f\"\\n**Top {n_emojis} most used emojis (emoji â€” frequency):**\\n\")\n",
    "for idx, (emoji, frequency) in enumerate(most_used_emojis, start=1):\n",
    "    print(f\"{idx:2d}. {emoji}   â€”   {frequency}\")\n",
    "\n",
    "# Top Mentions\n",
    "n_mentions = 10\n",
    "\n",
    "most_mentioned_users = top_mentioned_users(data_path, n=n_mentions)\n",
    "\n",
    "print(f\"\\n**Top {n_mentions} most mentioned users (user â€” frequency):**\\n\")\n",
    "for idx, (user, count) in enumerate(most_mentioned_users, start=1):\n",
    "    print(f\"{idx:2d}. {user}   â€”   {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
